{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf90094-a2ea-4a51-b262-b7ad0e005d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package shakespeare to\n",
      "[nltk_data]     /home/anthony/nltk_data...\n",
      "[nltk_data]   Package shakespeare is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/anthony/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/anthony/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('shakespeare')\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()\n",
    "bible = nltk.corpus.gutenberg.raw('bible-kjv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ccf694-0171-406b-9dbe-5c3a5e64f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = bible.find(\"The First Book of Moses\")\n",
    "end = bible.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
    "bible_clean = bible[start:end].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c96d974-a407-471f-84aa-3c65e413117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The First Book of Moses:  Called Genesis\\n\\n\\n1:1 In the beginning God created the heaven and the earth.\\n\\n1:2 And the earth was without form, and void; and darkness was upon\\nthe face of the deep. And the'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_clean[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1247308f-12d7-4f18-b3ac-87f309e18ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs/bible_kjv.txt\", \"w\") as f:\n",
    "    f.write(bible_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083a636f-9fbb-4d13-9631-ec359fe5d7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file saved at: data/bible/pretrain.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pretrain': 'data/bible/pretrain.jsonl'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.data_prep import make_pretrain_data\n",
    "\n",
    "make_pretrain_data(\n",
    "    source=\"docs/bible_kjv.txt\",\n",
    "    output_file=\"data/bible/pretrain.jsonl\",\n",
    "    entity=\"Bible\",\n",
    "    doc_type=\"scripture\",\n",
    "    inject=False,  # Keep it clean if you don't want artificial prefixes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c653992-3ee1-4135-9832-8d3682111b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tools.data_prep import make_pretrain_data, make_instruct_data\n",
    "\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d3daaa-7332-4ddc-be09-ebc149396201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported LlamaIndex\n"
     ]
    }
   ],
   "source": [
    "import pymupdf4llm\n",
    "llama_reader = pymupdf4llm.LlamaMarkdownReader()\n",
    "llama_docs = llama_reader.load_data(\"docs/anthony_cv.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe142c8-4f11-4fb8-80d9-7ec7f6be68e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='2a9f7005-f2a1-4b5e-95a8-f1feb2022ac2', embedding=None, metadata={'format': 'PDF 1.4', 'title': 'anthony_sun_cv_2025_s1', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Files', 'producer': 'iOS Version 18.3.1 (Build 22D72) Quartz PDFContext', 'creationDate': \"D:20250314115825Z00'00'\", 'modDate': \"D:20250314115825Z00'00'\", 'trapped': '', 'encryption': None, 'page': 1, 'total_pages': 4, 'file_path': 'docs/anthony_cv.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"12 Reserve Avenue, Mitcham, Victoria 3132 — Australian Citizen\\n# AN TH ON Y SU N\\n\\n**SENIOR MANAGER IN DATA SCIENCE, DATA INDUSTRIALISATION AND DATA MANAGEMENT**\\n\\n**PROFILE**\\n\\n\\n\\n\\nI am a hands-on senior leader with over 20 years of industry experience and in-depth\\ndomain knowledge of Credit Risk, Operational Risk and Financial Crime. I am also an\\nexpert in data engineering and data science, with a comprehensive understanding of\\nbanking products and data. I have led and accomplished numerous high-profile projects\\ndefining risk strategies leveraging my knowledge in machine learning and data\\nengineering.\\n\\nSome of the notable projects are:\\n\\n**Credit Risk:** Comprehensive Credit Reporting, Retail Lending Strategy with Multiple\\nBureau Data, Property Intelligence Hub, Bank Internal Bureau, Single Customer View,\\nCredit Decision Realtime Monitoring, Dynamic LVR optimisation, Pre-delinquent\\nModelling, Responsible Lending (RG209)\\n\\n**Financial Crime:** Application Fraud Clustering, NetReveal Case Management\\nOptimisation, Transaction Abuse Strategy.\\n\\n**Compliance:** BASEL 3, Comprehensive Model Monitoring, Model Validation Automation,\\nBanking Executive Accountability Framework\\n\\n**Operational Risk** : CPS220, Ops Risk Scenario Analysis, COVID workforce impact, Internal\\nFraud, Systemic Issues Identification.\\n\\nI have led teams across the above domains and owned data and analytics platforms.\\nProviding actionable insights to Group and Divisional CROs, Risk, and HR committees. And\\nproviding consultation and AI-based solutions to executive teams.\\n\\nI have managed teams of various sizes and structures, with both onshore and offshore\\npresence, and worked in collaboration with vendors such as Microsoft, Google, Experian,\\n\\nCoreLogic, IBM, PWC, etc.\\n\\nMy daily driver is continuous improvement and influencing strategy to produce efficient\\nand effective business outcomes.\\n\\n**EXPERIENCE**\\n\\n**PRINCIPAL SOLUTION DESIGNER**\\n\\n**DATA PLATFORMS (CREDIT RISK), WESTPAC — 2022 - 2024**\\n\\nIn my role, I have the privilege of leading a team of data solution designer to provide\\narchitecture design and data solution for risk data platforms. I've focused on building\\nstrong relationships between business and technology teams, which has been critical to\\nthe successful execution of multiple regulatory projects. I've also been able to introduce\\ndesign patterns that have streamlined our systems, improving overall efficiency.\\n\\nBeyond the technical aspects, my role involves engaging closely with the broader credit\\nrisk community. Using this collaborative approach, I've contributed to the strategic\\ndirection of our data solutions in credit risk. This teamwork has successfully completed\\ncritical projects like **B3, ECL, APS220, and Credit Risk Model Monitoring**, enhancing\\nour data-driven approach to risk management.\\n\\n\\n**EDUCATION**\\n\\n**University Of Melbourne, 2002**\\n\\n- Software Engineering (Honors)\\n\\n**RMIT, current**\\n\\n- Phd Candidate (Automated\\n\\nCompliance Checks with\\n\\nGenerative AI)\\n\\n**SKILLS**\\n\\n- **Statistical Model:** Linear/logistic\\n\\nregression; SVM, Decision Trees,\\n\\nDB scan, K-means, etc. NLP\\n\\nalgorithms such as word\\n\\nembedding, topical models, etc;\\n\\n- **Deep learning Model** : DNN\\n\\ndesign, CNN, RNN (LSTM, GRU,\\n\\netc)\\n\\n**Python** (data wrangling, machine\\n\\nlearning models, web-services)\\n\\n- **R** (data wrangling, Shiny\\n\\n\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4b66c280-f0b6-451d-9bc0-a7e01a4572a2', embedding=None, metadata={'format': 'PDF 1.4', 'title': 'anthony_sun_cv_2025_s1', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Files', 'producer': 'iOS Version 18.3.1 (Build 22D72) Quartz PDFContext', 'creationDate': \"D:20250314115825Z00'00'\", 'modDate': \"D:20250314115825Z00'00'\", 'trapped': '', 'encryption': None, 'page': 2, 'total_pages': 4, 'file_path': 'docs/anthony_cv.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='**SKILLS**\\n\\n- **Data Visualisation:** R-shiny,\\n\\nggplot, hi-chart, plot.ly, seaborn,\\n\\npython dash, QlikView, QlikSense,\\n\\nPower BI, SSRS, SAS VA\\n\\n**Data Processing** : SQL, SAS,\\n\\nTeradata, Spark, Ab initio, big data\\n\\nplatform such as Cloudera\\n\\n**Development** : J2EE, JMS, Tibco\\n\\nMQ\\n\\n- **Test Automation** : QTP, VBScript,\\n\\nSelenium, LoadRunner, Test\\n\\nComplete\\n\\n**Project Management** : Cert IV,\\n\\nAgile and other SDLC\\n\\n**Management** : Multiple teams/\\n\\ngeographies, recruitment,\\n\\nbudgeting, performance\\n\\n\\n#R, #Python, #Shiny, #SAS, #SQL, #SOLUTION, #ARCHITECTUR\\n\\n**HO DATA SCIENCE & INDUSTRIALISATION**\\n\\n**GROUP COMPLIANCE AND FIN CRIME, ANZ — 2018-2022**\\n\\nI lead teams of talented local and offshore product owners, data scientists, data analysts\\nand data engineers supporting Group Compliance in **advanced analytics, data**\\n**industrialisation** and **data management** . I am also the business owner of our analytics\\nplatforms ( **R Studio, IBM Watson** Studio), providing ongoing direction to advance our\\nanalytics capabilities.\\n\\nMy achievements are:\\n\\n- Established data science and data industrialisation functions\\n\\n- Developed **E2E analytics development framework** for both R and Python (from data\\ningestion and modelling to ongoing monitoring and calibration)\\n\\n- Established **data industrialisation principles** in alignment with **BCBS 239** requirements\\n\\n- Delivered **BEAR** accountability framework with T&C (HR) using a data-driven approach,\\ndelivering regular insights for chief risk officers and divisional leaders.\\n\\n- Led and delivered EMSBR (significant breach reporting) project, utilising **semi-**\\n**supervised clustering and classification (logistic regression)** techniques to identify\\nupcoming trends from risk events and complaints. (AFCA requirements)\\n\\n- Conducted analysis in **customer vulnerability detection** program, utilising **NLP** on\\ntransactional data to identify customers subject to sending/receiving abusive contents (See\\nfeatured news article)\\n\\n- **Feature engineering** and **unsupervised clustering** identify high-risk customer groups\\nfor **Financial Crime** and **Fraud** . (Using **logistic regression/random forest** for feature\\nselection, **k-means** and **grid search** for clustering) and identified customer clusters with\\nhigh fraud concentration.\\n\\n- Developed **R Shiny** tool utilising **visualisation** and NLP ( **word embedding**, **topic**\\n**modelling** ) in the Operational Risk Management uplift program ( **CPS 220** ). Significantly\\nsimplified process of policy requirement generation by automating matching and\\ndeduplicating existing obligations with new ORX taxonomy.\\n\\nMy team also provides ongoing **actionable insights** to the operational risk executive\\ncommittee. We have identified numerous systemic issues based on risk indicators.\\n\\n#R, #Python, #Shiny, #Tensorflow, #Natural Language Processing, #Recurrent Neural\\nNetwork, #Clustering (Risk Grading), #Data Management, #Automation,, #SQL, #LDA\\n\\n**SENIOR RISK MANAGER**\\n\\n**RETAIL CREDIT RISK, ANZ — 2014-2018**\\n\\nI have worked in multiple roles in Retail Credit Risk. Responsibility includes statistical\\nmodelling, business impact analysis and data visualisation. In addition, ongoing\\noptimisation of existing acquisitions/portfolio management strategies.\\n\\nMy achievements are:\\n\\n- Led analysis and implementation of **single customer view** (with Experian) to consolidate\\ncustomer profiles and holistically assess customer portfolios in the lending application\\nprocess. (To meet regulatory requirement **RG209** )\\n\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='167bc60e-8191-4a78-83bf-1b54364a26f8', embedding=None, metadata={'format': 'PDF 1.4', 'title': 'anthony_sun_cv_2025_s1', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Files', 'producer': 'iOS Version 18.3.1 (Build 22D72) Quartz PDFContext', 'creationDate': \"D:20250314115825Z00'00'\", 'modDate': \"D:20250314115825Z00'00'\", 'trapped': '', 'encryption': None, 'page': 3, 'total_pages': 4, 'file_path': 'docs/anthony_cv.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"- Implementation of DLVR **optimisation** to find optimum LVR allocation for the secured\\nlending book (thus capital requirement). Utilising python sci-pi and **parallel processing**, I\\nhave **reduced the processing time** for calculation DLVR **from 7 days to 5 minutes.**\\n\\n- Delivered E2E home loan **pre-delinquency mode** l via **Python/SAS** using **logistic**\\n**regression** and **decision tree** (class weighed on treatment cost) and utilising **SMOTE** to\\nupsample biased dataset.\\n\\n- Overdraft strategy design and implementation with Experian’s **PowerCurve Strategy**\\n**Manager**, implement policy rules on application, customer, capacity and performance\\ndata, and deliver decision strategy using customer and bureau scores.\\n\\n- Developed multi-customer multi-bureau (MCMB) framework using Experian’s\\n\\n**PowerCurve Enrichment** ;\\n\\n- Led and automated various data processing initiatives in credit risk, such as transactions\\ncategorisation to enable estimation of income and expenses; property intelligence hub to\\ntake a risk-based approach on home valuations in the lending decision; payday lending\\nflags; **(SAS DI, Python, pySpark** )\\n\\n- I have also automated data ingestion handling complex (bureaux) and unstructured data\\n(pdf documents) utilising big data platforms such as **ab initio** and **Cloudera** (with\\npy **Spark** ), **reducing reconciliation and reporting effort from 2 weeks to daily.**\\n\\n- **Visualisation** of credit decision performance, allowing **real-time monitoring** of\\napplication automation rate, customer segment, decision/referral reason waterfall, etc.\\n\\nI have coordinated several initiatives with internal risk, fraud, tech teams and external\\n\\nvendors such as Experian, Equifax, Billion and Corelogic. I was also a key decision\\ncontributor in multiple **vendor selection** programs. (PowerCurve, Ab initio, Customer\\nMatching)\\n\\n#SAS, #Python, #Spark, #ab Initio, #Qlik Sense, #R, #PowerCurve, #SQL, #Internal Bureau,\\n#Decision Tree, #Logistic Regression, #Scorecard, #Feature (characteristic) generation/\\n\\nselection, #QlikVew\\n\\n**LEAD PLATFORM DESIGNER**\\n\\n**GLOBAL CARDS PLATFORM, ANZ — 2012-1014**\\n\\nAs lead platform designer, I have led the design and delivery of the **credit decision**\\n**platform** provided by Experian ( **PowerCurve Originations** ) under the **comprehensive**\\n**credit reporting** (CCR) project, replacing the legacy mainframe-based decision system.\\n\\nMy achievements are:\\n\\n- We have implemented a world-first **PowerCurve-based** strategy supporting the\\nautomated decision for credit cards, personal loans, home loans and other secured/nonsecured lending portfolios.\\n\\n- Implemented high performing interface with **credit bureaux** and a decision workflow\\nsystem for manual override.\\n\\n- Developed framework to perform **automated decision simulation** utilising historical\\ndata to simulate lending applications and analyse new acquisition strategies'\\nperformance.\\n\\n- Delivered **Credit Analytics Database** for credit risk to monitor and analyse lending\\ndecisions in real-time and without performance impacts.\\n\\n- Delivered ANZ **Internal Bureau**, consolidating customer performance data and scores\\ninto a central location to support the automated decision.\\n\\n\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='5f0d4cfe-f5c1-498d-83ec-080f86f30a7e', embedding=None, metadata={'format': 'PDF 1.4', 'title': 'anthony_sun_cv_2025_s1', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Files', 'producer': 'iOS Version 18.3.1 (Build 22D72) Quartz PDFContext', 'creationDate': \"D:20250314115825Z00'00'\", 'modDate': \"D:20250314115825Z00'00'\", 'trapped': '', 'encryption': None, 'page': 4, 'total_pages': 4, 'file_path': 'docs/anthony_cv.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='#python, #java, #Powershell, #PowerCurve (EDSL), #soapUI, #MS SQL, #SSRS\\n\\n**AUTOMATION SOLUTIONS LEAD (VARIOUS ROLES)**\\n\\n**NABCAPITAL (WHOLESALE), NAB — 2008-2012**\\n\\nI worked in the Rates and Credit department at NAB Capital; my achievements are:\\n\\n- Integration workflow automation and **cash flow reconciliation** for successful upgrade/\\nmigration of platform Calypso.\\n\\n- Automated performance and integration testing utilisation I **BM MQ and Tibco EMS** .\\n\\n- Delivered **LoanIQ** upgrade and **Repurchase Agreement** projects.\\n\\n#IBM MQ, #EMS, #JMS, #Java, # Perl, #Calypso, #SQL, #LoanIQ, #BGM Model\\n\\n**OTHER ROLES**\\n\\n2008 — AUTOMATION CONSULTANT — SECURITIES INDUSTRY RESEARCH\\n\\nCENTER OF ASIA PACIFIC (SIRCA)\\n\\n2007 — TEST AUTOMATION LEAD — E*TRADE AUSTRALIA\\n\\n2004-2007 — SENIOR TEST ANALYST — IRESS\\n\\n2002- 2004 — QA ENGINEER — ATEX MEDIA COMMAND\\n\\n2002 — DEVELOPER — VERMONT TECHNOLOGY\\n\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6382dfda-9d23-4c57-8602-8d33e76520c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = pymupdf4llm.to_markdown(\"docs/anthony_cv.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a345ad-605f-4f12-94cc-4660f66c87da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Reserve Avenue, Mitcham, Victoria 3132 — Australian Citizen\n",
      "# AN TH ON Y SU N\n",
      "\n",
      "**SENIOR MANAGER IN DATA SCIENCE, DATA INDUSTRIALISATION AND DATA MANAGEMENT**\n",
      "\n",
      "**PROFILE**\n",
      "\n",
      "\n",
      "\n",
      "I am a hands-on senior leader with over 20 years of industry experience and in-depth\n",
      "domain knowledge of Credit Risk, Operational Risk and Financial Crime. I am also an\n",
      "expert in data engineering and data science, with a comprehensive understanding of\n",
      "banking products and data. I have led and accomplished numerous high-profile projects\n",
      "defining risk strategies leveraging my knowledge in machine learning and data\n",
      "engineering.\n",
      "\n",
      "Some of the notable projects are:\n",
      "\n",
      "**Credit Risk:** Comprehensive Credit Reporting, Retail Lending Strategy with Multiple\n",
      "Bureau Data, Property Intelligence Hub, Bank Internal Bureau, Single Customer View,\n",
      "Credit Decision Realtime Monitoring, Dynamic LVR optimisation, Pre-delinquent\n",
      "Modelling, Responsible Lending (RG209)\n",
      "\n",
      "**Financial Crime:** Application Fraud Clustering, NetReveal Case Management\n",
      "Optimisation, Transaction Abuse Strategy.\n",
      "\n",
      "**Compliance:** BASEL 3, Comprehensive Model Monitoring, Model Validation Automation,\n",
      "Banking Executive Accountability Framework\n",
      "\n",
      "**Operational Risk** : CPS220, Ops Risk Scenario Analysis, COVID workforce impact, Internal\n",
      "Fraud, Systemic Issues Identification.\n",
      "\n",
      "I have led teams across the above domains and owned data and analytics platforms.\n",
      "Providing actionable insights to Group and Divisional CROs, Risk, and HR committees. And\n",
      "providing consultation and AI-based solutions to executive teams.\n",
      "\n",
      "I have managed teams of various sizes and structures, with both onshore and offshore\n",
      "presence, and worked in collaboration with vendors such as Microsoft, Google, Experian,\n",
      "\n",
      "CoreLogic, IBM, PWC, etc.\n",
      "\n",
      "My daily driver is continuous improvement and influencing strategy to produce efficient\n",
      "and effective business outcomes.\n",
      "\n",
      "**EXPERIENCE**\n",
      "\n",
      "**PRINCIPAL SOLUTION DESIGNER**\n",
      "\n",
      "**DATA PLATFORMS (CREDIT RISK), WESTPAC — 2022 - 2024**\n",
      "\n",
      "In my role, I have the privilege of leading a team of data solution designer to provide\n",
      "architecture design and data solution for risk data platforms. I've focused on building\n",
      "strong relationships between business and technology teams, which has been critical to\n",
      "the successful execution of multiple regulatory projects. I've also been able to introduce\n",
      "design patterns that have streamlined our systems, improving overall efficiency.\n",
      "\n",
      "Beyond the technical aspects, my role involves engaging closely with the broader credit\n",
      "risk community. Using this collaborative approach, I've contributed to the strategic\n",
      "direction of our data solutions in credit risk. This teamwork has successfully completed\n",
      "critical projects like **B3, ECL, APS220, and Credit Risk Model Monitoring**, enhancing\n",
      "our data-driven approach to risk management.\n",
      "\n",
      "\n",
      "**EDUCATION**\n",
      "\n",
      "**University Of Melbourne, 2002**\n",
      "\n",
      "- Software Engineering (Honors)\n",
      "\n",
      "**RMIT, current**\n",
      "\n",
      "- Phd Candidate (Automated\n",
      "\n",
      "Compliance Checks with\n",
      "\n",
      "Generative AI)\n",
      "\n",
      "**SKILLS**\n",
      "\n",
      "- **Statistical Model:** Linear/logistic\n",
      "\n",
      "regression; SVM, Decision Trees,\n",
      "\n",
      "DB scan, K-means, etc. NLP\n",
      "\n",
      "algorithms such as word\n",
      "\n",
      "embedding, topical models, etc;\n",
      "\n",
      "- **Deep learning Model** : DNN\n",
      "\n",
      "design, CNN, RNN (LSTM, GRU,\n",
      "\n",
      "etc)\n",
      "\n",
      "**Python** (data wrangling, machine\n",
      "\n",
      "learning models, web-services)\n",
      "\n",
      "- **R** (data wrangling, Shiny\n",
      "\n",
      "**SKILLS**\n",
      "\n",
      "- **Data Visualisation:** R-shiny,\n",
      "\n",
      "ggplot, hi-chart, plot.ly, seaborn,\n",
      "\n",
      "python dash, QlikView, QlikSense,\n",
      "\n",
      "Power BI, SSRS, SAS VA\n",
      "\n",
      "**Data Processing** : SQL, SAS,\n",
      "\n",
      "Teradata, Spark, Ab initio, big data\n",
      "\n",
      "platform such as Cloudera\n",
      "\n",
      "**Development** : J2EE, JMS, Tibco\n",
      "\n",
      "MQ\n",
      "\n",
      "- **Test Automation** : QTP, VBScript,\n",
      "\n",
      "Selenium, LoadRunner, Test\n",
      "\n",
      "Complete\n",
      "\n",
      "**Project Management** : Cert IV,\n",
      "\n",
      "Agile and other SDLC\n",
      "\n",
      "**Management** : Multiple teams/\n",
      "\n",
      "geographies, recruitment,\n",
      "\n",
      "budgeting, performance\n",
      "\n",
      "\n",
      "#R, #Python, #Shiny, #SAS, #SQL, #SOLUTION, #ARCHITECTUR\n",
      "\n",
      "**HO DATA SCIENCE & INDUSTRIALISATION**\n",
      "\n",
      "**GROUP COMPLIANCE AND FIN CRIME, ANZ — 2018-2022**\n",
      "\n",
      "I lead teams of talented local and offshore product owners, data scientists, data analysts\n",
      "and data engineers supporting Group Compliance in **advanced analytics, data**\n",
      "**industrialisation** and **data management** . I am also the business owner of our analytics\n",
      "platforms ( **R Studio, IBM Watson** Studio), providing ongoing direction to advance our\n",
      "analytics capabilities.\n",
      "\n",
      "My achievements are:\n",
      "\n",
      "- Established data science and data industrialisation functions\n",
      "\n",
      "- Developed **E2E analytics development framework** for both R and Python (from data\n",
      "ingestion and modelling to ongoing monitoring and calibration)\n",
      "\n",
      "- Established **data industrialisation principles** in alignment with **BCBS 239** requirements\n",
      "\n",
      "- Delivered **BEAR** accountability framework with T&C (HR) using a data-driven approach,\n",
      "delivering regular insights for chief risk officers and divisional leaders.\n",
      "\n",
      "- Led and delivered EMSBR (significant breach reporting) project, utilising **semi-**\n",
      "**supervised clustering and classification (logistic regression)** techniques to identify\n",
      "upcoming trends from risk events and complaints. (AFCA requirements)\n",
      "\n",
      "- Conducted analysis in **customer vulnerability detection** program, utilising **NLP** on\n",
      "transactional data to identify customers subject to sending/receiving abusive contents (See\n",
      "featured news article)\n",
      "\n",
      "- **Feature engineering** and **unsupervised clustering** identify high-risk customer groups\n",
      "for **Financial Crime** and **Fraud** . (Using **logistic regression/random forest** for feature\n",
      "selection, **k-means** and **grid search** for clustering) and identified customer clusters with\n",
      "high fraud concentration.\n",
      "\n",
      "- Developed **R Shiny** tool utilising **visualisation** and NLP ( **word embedding**, **topic**\n",
      "**modelling** ) in the Operational Risk Management uplift program ( **CPS 220** ). Significantly\n",
      "simplified process of policy requirement generation by automating matching and\n",
      "deduplicating existing obligations with new ORX taxonomy.\n",
      "\n",
      "My team also provides ongoing **actionable insights** to the operational risk executive\n",
      "committee. We have identified numerous systemic issues based on risk indicators.\n",
      "\n",
      "#R, #Python, #Shiny, #Tensorflow, #Natural Language Processing, #Recurrent Neural\n",
      "Network, #Clustering (Risk Grading), #Data Management, #Automation,, #SQL, #LDA\n",
      "\n",
      "**SENIOR RISK MANAGER**\n",
      "\n",
      "**RETAIL CREDIT RISK, ANZ — 2014-2018**\n",
      "\n",
      "I have worked in multiple roles in Retail Credit Risk. Responsibility includes statistical\n",
      "modelling, business impact analysis and data visualisation. In addition, ongoing\n",
      "optimisation of existing acquisitions/portfolio management strategies.\n",
      "\n",
      "My achievements are:\n",
      "\n",
      "- Led analysis and implementation of **single customer view** (with Experian) to consolidate\n",
      "customer profiles and holistically assess customer portfolios in the lending application\n",
      "process. (To meet regulatory requirement **RG209** )\n",
      "\n",
      "- Implementation of DLVR **optimisation** to find optimum LVR allocation for the secured\n",
      "lending book (thus capital requirement). Utilising python sci-pi and **parallel processing**, I\n",
      "have **reduced the processing time** for calculation DLVR **from 7 days to 5 minutes.**\n",
      "\n",
      "- Delivered E2E home loan **pre-delinquency mode** l via **Python/SAS** using **logistic**\n",
      "**regression** and **decision tree** (class weighed on treatment cost) and utilising **SMOTE** to\n",
      "upsample biased dataset.\n",
      "\n",
      "- Overdraft strategy design and implementation with Experian’s **PowerCurve Strategy**\n",
      "**Manager**, implement policy rules on application, customer, capacity and performance\n",
      "data, and deliver decision strategy using customer and bureau scores.\n",
      "\n",
      "- Developed multi-customer multi-bureau (MCMB) framework using Experian’s\n",
      "\n",
      "**PowerCurve Enrichment** ;\n",
      "\n",
      "- Led and automated various data processing initiatives in credit risk, such as transactions\n",
      "categorisation to enable estimation of income and expenses; property intelligence hub to\n",
      "take a risk-based approach on home valuations in the lending decision; payday lending\n",
      "flags; **(SAS DI, Python, pySpark** )\n",
      "\n",
      "- I have also automated data ingestion handling complex (bureaux) and unstructured data\n",
      "(pdf documents) utilising big data platforms such as **ab initio** and **Cloudera** (with\n",
      "py **Spark** ), **reducing reconciliation and reporting effort from 2 weeks to daily.**\n",
      "\n",
      "- **Visualisation** of credit decision performance, allowing **real-time monitoring** of\n",
      "application automation rate, customer segment, decision/referral reason waterfall, etc.\n",
      "\n",
      "I have coordinated several initiatives with internal risk, fraud, tech teams and external\n",
      "\n",
      "vendors such as Experian, Equifax, Billion and Corelogic. I was also a key decision\n",
      "contributor in multiple **vendor selection** programs. (PowerCurve, Ab initio, Customer\n",
      "Matching)\n",
      "\n",
      "#SAS, #Python, #Spark, #ab Initio, #Qlik Sense, #R, #PowerCurve, #SQL, #Internal Bureau,\n",
      "#Decision Tree, #Logistic Regression, #Scorecard, #Feature (characteristic) generation/\n",
      "\n",
      "selection, #QlikVew\n",
      "\n",
      "**LEAD PLATFORM DESIGNER**\n",
      "\n",
      "**GLOBAL CARDS PLATFORM, ANZ — 2012-1014**\n",
      "\n",
      "As lead platform designer, I have led the design and delivery of the **credit decision**\n",
      "**platform** provided by Experian ( **PowerCurve Originations** ) under the **comprehensive**\n",
      "**credit reporting** (CCR) project, replacing the legacy mainframe-based decision system.\n",
      "\n",
      "My achievements are:\n",
      "\n",
      "- We have implemented a world-first **PowerCurve-based** strategy supporting the\n",
      "automated decision for credit cards, personal loans, home loans and other secured/nonsecured lending portfolios.\n",
      "\n",
      "- Implemented high performing interface with **credit bureaux** and a decision workflow\n",
      "system for manual override.\n",
      "\n",
      "- Developed framework to perform **automated decision simulation** utilising historical\n",
      "data to simulate lending applications and analyse new acquisition strategies'\n",
      "performance.\n",
      "\n",
      "- Delivered **Credit Analytics Database** for credit risk to monitor and analyse lending\n",
      "decisions in real-time and without performance impacts.\n",
      "\n",
      "- Delivered ANZ **Internal Bureau**, consolidating customer performance data and scores\n",
      "into a central location to support the automated decision.\n",
      "\n",
      "#python, #java, #Powershell, #PowerCurve (EDSL), #soapUI, #MS SQL, #SSRS\n",
      "\n",
      "**AUTOMATION SOLUTIONS LEAD (VARIOUS ROLES)**\n",
      "\n",
      "**NABCAPITAL (WHOLESALE), NAB — 2008-2012**\n",
      "\n",
      "I worked in the Rates and Credit department at NAB Capital; my achievements are:\n",
      "\n",
      "- Integration workflow automation and **cash flow reconciliation** for successful upgrade/\n",
      "migration of platform Calypso.\n",
      "\n",
      "- Automated performance and integration testing utilisation I **BM MQ and Tibco EMS** .\n",
      "\n",
      "- Delivered **LoanIQ** upgrade and **Repurchase Agreement** projects.\n",
      "\n",
      "#IBM MQ, #EMS, #JMS, #Java, # Perl, #Calypso, #SQL, #LoanIQ, #BGM Model\n",
      "\n",
      "**OTHER ROLES**\n",
      "\n",
      "2008 — AUTOMATION CONSULTANT — SECURITIES INDUSTRY RESEARCH\n",
      "\n",
      "CENTER OF ASIA PACIFIC (SIRCA)\n",
      "\n",
      "2007 — TEST AUTOMATION LEAD — E*TRADE AUSTRALIA\n",
      "\n",
      "2004-2007 — SENIOR TEST ANALYST — IRESS\n",
      "\n",
      "2002- 2004 — QA ENGINEER — ATEX MEDIA COMMAND\n",
      "\n",
      "2002 — DEVELOPER — VERMONT TECHNOLOGY\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(md_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbe334-8192-440a-bc36-c32c69797a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
